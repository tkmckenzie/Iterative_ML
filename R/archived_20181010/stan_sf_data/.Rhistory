source('~/code/R/test.R', echo=TRUE)
source('~/code/R/test.R', echo=TRUE)
source('~/code/R/test.R', echo=TRUE)
names(df)
source('~/code/R/test.R', echo=TRUE)
source('~/code/R/test.R', echo=TRUE)
ggplot(df, aes(X, Y)) + geom_line(aes(color = Type)) + xytheme
source('~/code/R/test.R', echo=TRUE)
source('~/code/R/test.R', echo=TRUE)
source('~/code/R/test.R', echo=TRUE)
(565.31 / .13) * .03
2820 + 2950
5570 * 26
144820 / 230000
2817 / 4423
52 * 7
2820*52
2820*26
74 + 75
40000 / 149000
1024 * 8
2900 * 26
install.packages("installr")
library(installr)
updateR()
57842/70439
source('~/code/PE/24.R', echo=TRUE)
first.char = which(sapply(1:(length(x) - 1), function(i) x[i + 1] < x[i]))[1]
length(first.char)
sapply(1:(length(x) - 1), function(i) x[i + 1] < x[i])
first.char
first.char = which(sapply(1:(length(x) - 1), function(i) x[i] < x[i + 1]))[1]
x = c(4, 3, 6, 5, 2, 1)
first.char = which(sapply(1:(length(x) - 1), function(i) x[i] < x[i + 1]))[1]
first.char.index = which(sapply(1:(length(x) - 1), function(i) x[i] < x[i + 1]))[1]
first.char = x[first.char.index]
second.char.index = which(x > first.char)
second.char.index = second.char.index[second.char.index > first.char.index][1]
second.char.index
first.char.index = which(sapply(1:(length(x) - 1), function(i) x[i] < x[i + 1]))[1]
first.char = x[first.char.index]
second.char.index = which(x > first.char)
second.char.index[second.char.index > first.char.index]
second.char.index = second.char.index[second.char.index > first.char.index][1]
second.char = x[second.char.index]
first.char.index = which(sapply(1:(length(x) - 1), function(i) x[i] < x[i + 1]))[1]
first.char = x[first.char.index]
x.subset = x[-(1:first.char.index)]
second.char = min(x.subset[x.subset > first.char])
second.char.index = which(x == second.char)
first.char.index = which(sapply(1:(length(x) - 1), function(i) x[i] < x[i + 1]))[1]
first.char = x[first.char.index]
x.subset = x[-(1:first.char.index)]
second.char = min(x.subset[x.subset > first.char])
second.char.index = which(x == second.char)
x[first.char.index] = second.char
x[second.char.index] = first.char
x[-(1:first.char.index)] = sort(x[-(1:first.char.index)])
source('~/code/PE/24.R', echo=TRUE)
x = 0:2
first.char.index = which(sapply(1:(length(x) - 1), function(i) x[i] < x[i + 1]))[1]
first.char = x[first.char.index]
x.subset = x[-(1:first.char.index)]
second.char = min(x.subset[x.subset > first.char])
second.char.index = which(x == second.char)
x[first.char.index] = second.char
x[second.char.index] = first.char
x[-(1:first.char.index)]
sort(x[-(1:first.char.index)])
x
x[-(1:first.char.index)] = sort(x[-(1:first.char.index)])
source('~/code/PE/24.R', echo=TRUE)
source('~/code/PE/24.R', echo=TRUE)
source('~/code/PE/24.R', echo=TRUE)
source('~/code/PE/24.R', echo=TRUE)
x = iterate(x)
x = iterate(x)
x = iterate(x)
x = iterate(x)
x = iterate(x)
x = iterate(x)
source('~/code/PE/24.R', echo=TRUE)
source('~/code/PE/24.R', echo=TRUE)
source('~/code/PE/24.R', echo=TRUE)
source('~/code/PE/24.R', echo=TRUE)
source('~/code/PE/24.R', echo=TRUE)
paste0(x, collapse = "")
rm(list = ls())
27 + 36
90/020
62000*9
64757 + 2536
60721+671+81+5820
source('~/code/R/smoothing/npbr_test/snfa_quantity.R', echo=TRUE)
log(1 / exp(1))
source('~/code/R/smoothing/npbr_test/snfa_expenditure.R', echo=TRUE)
source('~/code/R/smoothing/npbr_test/snfa_expenditure.R', echo=TRUE)
log(1 / (log(1 / beta.K)))
log(1 / (log(1 / beta.L)))
source('~/code/R/smoothing/npbr_test/snfa_quantity.R', echo=TRUE)
source('~/code/R/smoothing/npbr_test/snfa_quantity.R', echo=TRUE)
source('~/code/R/smoothing/npbr_test/snfa_expenditure.R', echo=TRUE)
source('~/code/R/smoothing/npbr_test/snfa_expenditure.R', echo=TRUE)
source('~/code/R/smoothing/npbr_test/snfa_expenditure.R', echo=TRUE)
rm(list = ls())
#Parameters
N = 100
k = 2
A = 10
beta.K = 1/exp(1)
beta.L = 1/4
#Biases, positive is overallocation
w.K.bias = 0
w.L.bias = 0
num.reps = 50
estimates = matrix(NA, ncol = k)
#Data
K = runif(N, 25, 50)
L = runif(N, 10, 30)
efficiency = exp(-abs(rnorm(N, sd = 0.1)))
# efficiency = 1
Y = A * K^beta.K * L^beta.L * efficiency
dY.dK = A * beta.K * K^(beta.K - 1) * L^beta.L * efficiency
dY.dL = A * beta.L * K^beta.K * L^(beta.L - 1) * efficiency
p = rnorm(N, mean = 10, sd = 1)
dR.dK = p * dY.dK
dR.dL = p * dY.dL
w.K.star = p * dY.dK * efficiency
w.L.star = p * dY.dL * efficiency
w.K = w.K.star * exp(w.K.bias)
w.L = w.L.star * exp(w.L.bias)
#Calculate mean overallocation
price.ratio = cbind(w.K / p, w.L / p)
gradient = cbind(dY.dK, dY.dL)
log.overallocation = log(price.ratio) - log(gradient * efficiency)
apply(log.overallocation, 2, mean)
#Calculate mean overallocation
price.ratio = cbind(rep(1, N), rep(1, N))
#Calculate mean overallocation
price.ratio = cbind(rep(1, N), rep(1, N))
gradient = cbind(dY.dK * p / w.K.star, dY.dL * p / w.L.star)
log.overallocation = log(price.ratio) - log(gradient * efficiency)
apply(log.overallocation, 2, mean)
#Construct expenditure variables
X = cbind(K * w.K, L * w.L)
X.price = matrix(1, nrow = nrow(X), ncol = ncol(X))
y = Y * p
y.price = rep(1, N)
method = "mc"
model = "br"
H.inv = NA
H.mult = 1
X.constrained = NA
if (!(model %in% c("br", "sf"))) stop("model must be \"br\" or \"sf\".")
if ((nrow(X) != length(y)) | (nrow(X) != nrow(X.price)) | (nrow(X) != length(y.price))) stop("X, y, X.price, and y.price must have same number of observations.")
if (ncol(X) != ncol(X.price)) stop("X must have same number of columns as X.price.")
N = nrow(X)
#Reflect data for fitting
reflected.data = reflect.data(X, y)
X.eval = reflected.data$X.reflected
y.eval = reflected.data$y.reflected
if (any(is.na(X.constrained))){
X.constrained = X
}
if (any(is.na(H.inv))){
H.inv = H.inv.select(X, H.mult = H.mult)
}
m = fit.boundary(X.eval, y.eval, X, y, X.constrained, X, y, H.inv, H.mult, method)
technical.efficiency = m$efficiency
gradient = as.matrix(m$gradient.fit)
apply(X.price, 2, function(col) col / y.price)
price.ratio
#Compute mraginal productivities
marginal.productivities = apply(gradient, 2, function(col) col * technical.efficiency)
marginal.productivities
gradient
marginal.productivities / gradient
apply(marginal.productivities / gradient, 2, mean)
#Data
K = runif(N, 25, 50)
L = runif(N, 10, 30)
efficiency = exp(-abs(rnorm(N, sd = 0.1)))
# efficiency = 1
Y = A * K^beta.K * L^beta.L * efficiency
dY.dK = A * beta.K * K^(beta.K - 1) * L^beta.L * efficiency
dY.dL = A * beta.L * K^beta.K * L^(beta.L - 1) * efficiency
p = rnorm(N, mean = 10, sd = 1)
dR.dK = p * dY.dK
dR.dL = p * dY.dL
w.K.star = p * dY.dK * efficiency
w.L.star = p * dY.dL * efficiency
w.K = w.K.star * exp(w.K.bias)
w.L = w.L.star * exp(w.L.bias)
#Calculate mean overallocation
price.ratio = cbind(rep(1, N), rep(1, N))
gradient = cbind(dY.dK * p / w.K.star, dY.dL * p / w.L.star)
log.overallocation = log(price.ratio) - log(gradient * efficiency)
apply(log.overallocation, 2, mean)
#Construct expenditure variables
X = cbind(K * w.K, L * w.L)
X.price = matrix(1, nrow = nrow(X), ncol = ncol(X))
y = Y * p
y.price = rep(1, N)
method = "mc"
model = "br"
H.inv = NA
H.mult = 1
X.constrained = NA
#Run model:
m.e = allocative.efficiency(X, y, X.price, y.price, method = "mc", model = "br", H.inv = NA, H.mult = 1)
m.e$gradient.fit / gradient
if (!(model %in% c("br", "sf"))) stop("model must be \"br\" or \"sf\".")
if ((nrow(X) != length(y)) | (nrow(X) != nrow(X.price)) | (nrow(X) != length(y.price))) stop("X, y, X.price, and y.price must have same number of observations.")
if (ncol(X) != ncol(X.price)) stop("X must have same number of columns as X.price.")
N = nrow(X)
#Reflect data for fitting
reflected.data = reflect.data(X, y)
X.eval = reflected.data$X.reflected
y.eval = reflected.data$y.reflected
if (any(is.na(X.constrained))){
X.constrained = X
}
if (any(is.na(H.inv))){
H.inv = H.inv.select(X, H.mult = H.mult)
}
m = fit.boundary(X.eval, y.eval, X, y, X.constrained, X, y, H.inv, H.mult, method)
technical.efficiency = m$efficiency
gradient = as.matrix(m$gradient.fit)
#Compute price ratios
price.ratio = apply(X.price, 2, function(col) col / y.price)
#Compute mraginal productivities
marginal.productivities = apply(gradient, 2, function(col) col * technical.efficiency)
marginal.productivities / gradient
apply(marginal.productivities / gradient, 2, mean)
source('~/code/R/smoothing/npbr_test/snfa_expenditure.R', echo=TRUE)
A = 10
beta.K = 1/exp(1)
beta.L = 1/4
#Biases, positive is overallocation
w.K.bias = 0
w.L.bias = 0
num.reps = 50
estimates = matrix(NA, ncol = k)
#Data
K = runif(N, 25, 50)
L = runif(N, 10, 30)
efficiency = exp(-abs(rnorm(N, sd = 0.1)))
# efficiency = 1
Y = A * K^beta.K * L^beta.L * efficiency
dY.dK = A * beta.K * K^(beta.K - 1) * L^beta.L * efficiency
dY.dL = A * beta.L * K^beta.K * L^(beta.L - 1) * efficiency
p = rnorm(N, mean = 10, sd = 1)
dR.dK = p * dY.dK
dR.dL = p * dY.dL
w.K.star = p * dY.dK * efficiency
w.L.star = p * dY.dL * efficiency
w.K = w.K.star * exp(w.K.bias)
w.L = w.L.star * exp(w.L.bias)
#Calculate mean overallocation
price.ratio = cbind(rep(1, N), rep(1, N))
gradient = cbind(dY.dK * p / w.K.star, dY.dL * p / w.L.star)
log.overallocation = log(price.ratio) - log(gradient * efficiency)
apply(log.overallocation, 2, mean)
#Construct expenditure variables
X = cbind(K * w.K, L * w.L)
X.price = matrix(1, nrow = nrow(X), ncol = ncol(X))
y = Y * p
y.price = rep(1, N)
method = "mc"
model = "br"
H.inv = NA
H.mult = 1
X.constrained = NA
#Run model:
m.e = allocative.efficiency(X, y, X.price, y.price, method = "mc", model = "br", H.inv = NA, H.mult = 1)
m.e$gradient.fit / gradient
apply(m.e$gradient.fit / gradient, 2, mean)
log.overallocation = log(price.ratio) - log(gradient)
apply(log.overallocation, 2, mean)
#Calculate mean overallocation
price.ratio = cbind(w.K / p, w.L / p)
gradient = cbind(dY.dK, dY.dL)
log.overallocation = log(price.ratio) - log(gradient)
apply(log.overallocation, 2, mean)
source('~/code/R/smoothing/npbr_test/snfa_expenditure.R', echo=TRUE)
#Data
K = runif(N, 25, 50)
L = runif(N, 10, 30)
efficiency = exp(-abs(rnorm(N, sd = 0.1)))
# efficiency = 1
Y = A * K^beta.K * L^beta.L * efficiency
dY.dK = A * beta.K * K^(beta.K - 1) * L^beta.L * efficiency
dY.dL = A * beta.L * K^beta.K * L^(beta.L - 1) * efficiency
p = rnorm(N, mean = 10, sd = 1)
dR.dK = p * dY.dK
dR.dL = p * dY.dL
w.K.star = p * dY.dK
w.L.star = p * dY.dL
w.K = w.K.star * exp(w.K.bias)
w.L = w.L.star * exp(w.L.bias)
#Calculate mean overallocation
price.ratio = cbind(w.K / p, w.L / p)
gradient = cbind(dY.dK, dY.dL)
log.overallocation = log(price.ratio) - log(gradient)
apply(log.overallocation, 2, mean)
X
source('~/code/R/smoothing/npbr_test/snfa_expenditure.R', echo=TRUE)
source('~/code/R/smoothing/npbr_test/snfa_quantity.R', echo=TRUE)
source('~/code/R/smoothing/npbr_test/snfa_expenditure.R', echo=TRUE)
source('~/code/R/smoothing/npbr_test/snfa_expenditure.R', echo=TRUE)
1 / exp(1)
log(1 / exp(1))
log(1 / (log(4)))
gradient / m.e$gradient.fit
gradient / (m.e$gradient.fit * m.e$technical.efficiency)
apply(gradient / (m.e$gradient.fit * m.e$technical.efficiency), 2, mean)
gradient
efficiency
gradient / efficiency
0.8316379 / 0.9628091
0.8232811 / 0.9628091
0.8239839 / 0.9807970
apply((gradient / efficiency) / m.e$gradient.fit, 2, mean)
apply(apply(gradient, 2, function(col) col / efficiency) / m.e$gradient.fit, 2, mean)
apply(gradient / apply(m.e$gradient.fit, 2, function(col) col * efficiency), 2, mean)
source('~/code/R/smoothing/npbr_test/snfa_expenditure.R', echo=TRUE)
source('~/code/R/smoothing/npbr_test/snfa_expenditure.R', echo=TRUE)
apply(gradient.ratio, 2, meaa)
apply(gradient.ratio, 2, mean)
gradient.ratio
apply(gradient.ratio, 2, mean, na.rm = T)
apply(gradient.ratio, 2, median, na.rm = T)
source('~/code/R/smoothing/npbr_test/snfa_expenditure.R', echo=TRUE)
source('~/code/R/smoothing/npbr/snfa_package/snfa/R/allocative.efficiency.R', echo=TRUE)
source('~/code/R/smoothing/npbr_test/snfa_expenditure.R', echo=TRUE)
efficiency
m.e$technical.efficiency
5 * 1000
5 * 1000 / 3600
source('~/git/tyche/kalman/create_data.R', echo=TRUE)
source('~/git/tyche/kalman/kalman_fit.R', echo=TRUE)
library(ggplot2)
library(rstan)
setwd("~/git/Iterative_ML/R/stan_sf_data")
rm(list = ls())
load("data.RData")
burn.iter = 9000
sample.iter = 1000
burn.iter = 1
sample.iter = 1
load("stan_gp_sf.dso")
stan.data = list(N = nrow(X), k = ncol(X), X = X, y = y,
alpha_prior_sd = 1,
H_inv_diag_prior_shape = 0.1,
H_inv_diag_prior_rate = 0.1)
stan.fit = stan("stan_gp_sf.stan", data = stan.data,
control = list(adapt_delta = 0.9),
chains = 1, iter = burn.iter + sample.iter, warmup = burn.iter)
stan.fit = stan("stan_gp_sf.stan", data = stan.data,
control = list(adapt_delta = 0.9),
chains = 1, iter = burn.iter + sample.iter, warmup = burn.iter)
stan.fit = stan("stan_gp_sf.stan", data = stan.data,
control = list(adapt_delta = 0.9),
chains = 1, iter = burn.iter + sample.iter, warmup = burn.iter)
save(stan.fit, file = "stan_gp_sf.dso")
source('~/git/Iterative_ML/R/stan_sf_data/gp_sf_fit.R', echo=TRUE)
source('~/git/Iterative_ML/R/stan_sf_data/gp_sf_fit.R', echo=TRUE)
#Trace plot:
traceplot(stan.fit)
source('~/git/Iterative_ML/R/stan_sf_data/par_sf_fit.R', echo=TRUE)
load("stan_par_fits/stan_par_sf_unconditional.RData")
stan.extract = extract(stan.fit)
#Plot
e = apply(t(sapply(1:sample.iter, function(i) y - (stan.extract$beta_const[i] + X %*% stan.extract$beta[i,]))), 2, mean)
plot(e ~ y)
#Trace plot:
traceplot(stan.fit)
#Efficiency estimates
u.mode = function(i){
epsilon = y - (stan.extract$beta_const[i] + X %*% stan.extract$beta[i,])
sigma.u = stan.extract$sigma_u[i]
sigma.v = stan.extract$sigma_v[i]
sigma.sq = sigma.u^2 + sigma.v^2
raw.epsilon = -epsilon * (sigma.u^2 / sigma.sq)
return(ifelse(raw.epsilon < 0, raw.epsilon, 0))
}
u.mean = function(i){
epsilon = y - (stan.extract$beta_const[i] + X %*% stan.extract$beta[i,])
sigma.u = stan.extract$sigma_u[i]
sigma.v = stan.extract$sigma_v[i]
sigma.sq = sigma.u^2 + sigma.v^2
sigma = sqrt(sigma.sq)
mu.star = -sigma.u^2 * epsilon / sigma.sq
sigma.sq.star = sigma.u^2 * sigma.v^2 / sigma.sq
sigma.star = sqrt(sigma.sq.star)
lambda = sigma.u / sigma.v
eval.point = epsilon * lambda / sigma
# return(mu.star + sigma.star * dnorm(-mu.star / sigma.star) / (1 - pnorm(-mu.star / sigma.star)))
return(-sigma.star * (dnorm(eval.point) / (1 - pnorm(eval.point)) - eval.point))
}
u.posterior = t(sapply(1:sample.iter, u.mean))
apply(exp(u.posterior), 2, mean)
cbind(countries, apply(exp(u.posterior), 2, mean))
#Other posterior estimates
# mean(exp(sapply(1:sample.iter, function(i) -sqrt(2 / pi) * stan.extract$sigma_u[i])))
# mean(exp(-stan.extract$sigma_u))
median(stan.extract$sigma_u)
median(stan.extract$sigma_v)
##############################
#Likelihood evaluation
N = nrow(X)
log.lik.func = function(epsilon, sigma.u, sigma.v){
sigma.sq = sigma.u^2 + sigma.v^2
sigma = sqrt(sigma.sq)
lambda = sigma.u / sigma.v
return(length(epsilon) * (log(2) - log(sigma)) + dnorm(epsilon / sigma, log = TRUE) + pnorm(epsilon * lambda / sigma, log = TRUE, lower.tail = FALSE))
}
sigma.u.restricted = mean(stan.extract$sigma_u)
sigma.v.restricted = mean(stan.extract$sigma_v)
beta.const.restricted = mean(stan.extract$beta_const)
beta.restricted = mean(stan.extract$beta)
f = beta.const.restricted + X %*% beta.restricted
epsilon = c(y - f)
log.lik = sum(sapply(epsilon, log.lik.func, sigma.u = sigma.u.restricted, sigma.v = sigma.v.restricted))
log.lik
beta.restricted = apply(stan.extract$beta, 2, mean)
f = beta.const.restricted + X %*% beta.restricted
epsilon = c(y - f)
log.lik = sum(sapply(epsilon, log.lik.func, sigma.u = sigma.u.restricted, sigma.v = sigma.v.restricted))
log.lik
source('~/git/Iterative_ML/R/stan_sf_data/par_translog_sf_fit.R', echo=TRUE)
source('~/git/Iterative_ML/R/stan_sf_data/par_translog_sf_fit.R', echo=TRUE)
source('~/git/Iterative_ML/R/stan_sf_data/par_translog_sf_fit.R', echo=TRUE)
source('~/git/Iterative_ML/R/stan_sf_data/gp_sf_fit.R', echo=TRUE)
source('~/git/Iterative_ML/R/stan_sf_data/gp_sf_fit.R', echo=TRUE)
